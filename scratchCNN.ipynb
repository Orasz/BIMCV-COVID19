{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwBEQ5os+mGWbDXU2qt8uH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Orasz/CNN4COVID19/blob/main/scratchCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykovEOkLAwmY",
        "outputId": "40c06bc4-15e6-410a-8d61-d22bec5f4ce7"
      },
      "source": [
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)\r\n",
        "\r\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbBMqMVRA5zH",
        "outputId": "d26754b3-c54b-49eb-bd8b-514858d51b50"
      },
      "source": [
        "\r\n",
        "\r\n",
        "from __future__ import print_function, division\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import numpy as np\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, models, transforms\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n",
        "import os\r\n",
        "import copy\r\n",
        "from torchsummary import summary\r\n",
        "\r\n",
        "plt.ion()   # interactive mode\r\n",
        "print(\"done\")\r\n",
        "\r\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbotxk5LBJNw",
        "outputId": "5215fa47-67a0-4a82-d6fd-ab2c235b463f"
      },
      "source": [
        "# Data augmentation and normalization for training\r\n",
        "# Just normalization for validation\r\n",
        "\r\n",
        "data_transforms_xray = {\r\n",
        "    'train': transforms.Compose([\r\n",
        "        transforms.Resize(256),\r\n",
        "        transforms.CenterCrop(256),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ]),\r\n",
        "    'val': transforms.Compose([\r\n",
        "        transforms.Resize(256),\r\n",
        "        transforms.CenterCrop(256),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ]),\r\n",
        "        'test': transforms.Compose([\r\n",
        "        transforms.Resize(256),\r\n",
        "        transforms.CenterCrop(256),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ])\r\n",
        "}\r\n",
        "\r\n",
        "data_dir = 'gdrive/MyDrive/datasetQaTa/'\r\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\r\n",
        "                                          data_transforms_xray[x])\r\n",
        "                  for x in ['train', 'val']}\r\n",
        "#aumenta batch size \r\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\r\n",
        "                                             shuffle=True, num_workers=4)\r\n",
        "              for x in ['train', 'val']}\r\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\r\n",
        "print(\"Dataset sizes: {}\".format(dataset_sizes))\r\n",
        "class_names = image_datasets['train'].classes\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(\"using device: {}\".format(device))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset sizes: {'train': 7375, 'val': 940}\n",
            "using device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-52PWHDBF4E",
        "outputId": "baa6d806-8816-4be4-ea4c-698cbb1e9be0"
      },
      "source": [
        "class ScratchCNN(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(ScratchCNN, self).__init__()\r\n",
        "        \r\n",
        "        self.model = nn.Sequential(\r\n",
        "            nn.Conv2d(3, 16, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(16, 16, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2,2),\r\n",
        "\r\n",
        "            nn.Conv2d(16, 32, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(32, 32, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2,2),\r\n",
        "\r\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(64, 64, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2,2),\r\n",
        "\r\n",
        "            nn.Conv2d(64, 128, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(128, 128, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2,2),\r\n",
        "\r\n",
        "            nn.Conv2d(128, 256, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(256, 256, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2,2),\r\n",
        "\r\n",
        "        ).to(device)\r\n",
        "        \r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            nn.Flatten(),\r\n",
        "            nn.Dropout(0.25),\r\n",
        "            nn.Linear(4096, 256),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout(0.25),\r\n",
        "            nn.Linear(256, 2)\r\n",
        "        ).to(device)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.model(x)\r\n",
        "        x = self.classifier(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "model = ScratchCNN().to(device)\r\n",
        "summary(model, (3,256,256))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 254, 254]             448\n",
            "              ReLU-2         [-1, 16, 254, 254]               0\n",
            "            Conv2d-3         [-1, 16, 252, 252]           2,320\n",
            "              ReLU-4         [-1, 16, 252, 252]               0\n",
            "         MaxPool2d-5         [-1, 16, 126, 126]               0\n",
            "            Conv2d-6         [-1, 32, 124, 124]           4,640\n",
            "              ReLU-7         [-1, 32, 124, 124]               0\n",
            "            Conv2d-8         [-1, 32, 122, 122]           9,248\n",
            "              ReLU-9         [-1, 32, 122, 122]               0\n",
            "        MaxPool2d-10           [-1, 32, 61, 61]               0\n",
            "           Conv2d-11           [-1, 64, 59, 59]          18,496\n",
            "             ReLU-12           [-1, 64, 59, 59]               0\n",
            "           Conv2d-13           [-1, 64, 57, 57]          36,928\n",
            "             ReLU-14           [-1, 64, 57, 57]               0\n",
            "        MaxPool2d-15           [-1, 64, 28, 28]               0\n",
            "           Conv2d-16          [-1, 128, 26, 26]          73,856\n",
            "             ReLU-17          [-1, 128, 26, 26]               0\n",
            "           Conv2d-18          [-1, 128, 24, 24]         147,584\n",
            "             ReLU-19          [-1, 128, 24, 24]               0\n",
            "        MaxPool2d-20          [-1, 128, 12, 12]               0\n",
            "           Conv2d-21          [-1, 256, 10, 10]         295,168\n",
            "             ReLU-22          [-1, 256, 10, 10]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-24            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-25            [-1, 256, 4, 4]               0\n",
            "          Flatten-26                 [-1, 4096]               0\n",
            "          Dropout-27                 [-1, 4096]               0\n",
            "           Linear-28                  [-1, 256]       1,048,832\n",
            "             ReLU-29                  [-1, 256]               0\n",
            "          Dropout-30                  [-1, 256]               0\n",
            "           Linear-31                    [-1, 2]             514\n",
            "================================================================\n",
            "Total params: 2,228,114\n",
            "Trainable params: 2,228,114\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 59.16\n",
            "Params size (MB): 8.50\n",
            "Estimated Total Size (MB): 68.41\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nh8iBF8CdcY"
      },
      "source": [
        "lr = 0.00001\r\n",
        "model = ScratchCNN().to(device)\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnaV0o3VCqcV"
      },
      "source": [
        "def Train(model, epoch, print_every=len(dataloaders['train'])):\r\n",
        "    total_loss = 0\r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    accuracy = []\r\n",
        "    \r\n",
        "    for i, batch in enumerate(dataloaders['train'], 1):\r\n",
        "        minput = batch[0].to(device) # Get batch of images from our train dataloader\r\n",
        "        target = batch[1].to(device) # Get the corresponding target(0, 1 or 2) representing cats, dogs or pandas\r\n",
        "        \r\n",
        "        moutput = model(minput) # output by our model\r\n",
        "        \r\n",
        "        loss = criterion(moutput, target) # compute cross entropy loss\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        optimizer.zero_grad() # Clear the gradients if exists. (Gradients are used for back-propogation.)\r\n",
        "        loss.backward() # Back propogate the losses\r\n",
        "        optimizer.step() # Update Model parameters\r\n",
        "        \r\n",
        "        argmax = moutput.argmax(dim=1) # Get the class index with maximum probability predicted by the model\r\n",
        "        accuracy.append((target==argmax).sum().item() / target.shape[0]) # calculate accuracy by comparing to target tensor\r\n",
        "\r\n",
        "        if i%print_every == 0:\r\n",
        "            print('Epoch: [{}]/({}/{}), Train Loss: {:.4f}, Accuracy: {:.2f}, Time: {:.2f} sec'.format(\r\n",
        "                epoch, i, len(dataloaders['train']), loss.item(), sum(accuracy)/len(accuracy), time.time()-start_time \r\n",
        "            ))\r\n",
        "    \r\n",
        "    return total_loss / len(dataloaders['train']) # Returning Average Training Loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKaLxh_4DKOh"
      },
      "source": [
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\r\n",
        "                                          data_transforms_xray[x])\r\n",
        "                  for x in ['train', 'val', 'test']}\r\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\r\n",
        "                                             shuffle=True, num_workers=4)\r\n",
        "              for x in ['train', 'val','test']}\r\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val','test']}"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hikcw_TcZRah"
      },
      "source": [
        "def Test(model,epoch):\r\n",
        "    total_loss = 0\r\n",
        "    start_time = time.time()\r\n",
        "\r\n",
        "    accuracy = []\r\n",
        "    \r\n",
        "    with torch.no_grad(): # disable calculations of gradients for all pytorch operations inside the block\r\n",
        "        for i, batch in enumerate(dataloaders['test']):\r\n",
        "            minput = batch[0].to(device) # Get batch of images from our test dataloader\r\n",
        "            target = batch[1].to(device) # Get the corresponding target(0, 1 or 2) representing cats, dogs or pandas\r\n",
        "            moutput = model(minput) # output by our model\r\n",
        "\r\n",
        "            loss = criterion(moutput, target) # compute cross entropy loss\r\n",
        "            total_loss += loss.item()\r\n",
        "            \r\n",
        "            \r\n",
        "            # To get the probabilities for different classes we need to apply a softmax operation on moutput \r\n",
        "            argmax = moutput.argmax(dim=1) # Find the index(0, 1 or 2) with maximum score (which denotes class with maximum probability)\r\n",
        "            accuracy.append((target==argmax).sum().item() / target.shape[0]) # Find the accuracy of the batch by comparing it with actual targets\r\n",
        "            \r\n",
        "    print('Epoch: [{}], Test Loss: {:.4f}, Accuracy: {:.2f}, Time: {:.2f} sec'.format(\r\n",
        "        epoch, total_loss/len(dataloaders['test']), sum(accuracy)/len(accuracy), time.time()-start_time\r\n",
        "    ))\r\n",
        "    return total_loss/len(dataloaders['test']) # Returning Average Testing Loss"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM9AqOR0Dyc0",
        "outputId": "c83df2a7-2230-4d2f-80f0-adc0bf640750"
      },
      "source": [
        "\r\n",
        "Test(model,0)\r\n",
        "\r\n",
        "train_loss = []\r\n",
        "test_loss = []\r\n",
        "\r\n",
        "for epoch in range(1, 51):\r\n",
        "    train_loss.append(Train(model,epoch,200))\r\n",
        "    test_loss.append(Test(model,epoch))\r\n",
        "\r\n",
        "    print('\\n')\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0], Test Loss: 0.6934, Accuracy: 0.50, Time: 4.71 sec\n",
            "Epoch: [1]/(200/461), Train Loss: 0.6937, Accuracy: 0.49, Time: 17.63 sec\n",
            "Epoch: [1]/(400/461), Train Loss: 0.6936, Accuracy: 0.49, Time: 34.78 sec\n",
            "Epoch: [1], Test Loss: 0.6926, Accuracy: 0.50, Time: 4.74 sec\n",
            "\n",
            "\n",
            "Epoch: [2]/(200/461), Train Loss: 0.6194, Accuracy: 0.58, Time: 17.51 sec\n",
            "Epoch: [2]/(400/461), Train Loss: 0.5751, Accuracy: 0.64, Time: 34.89 sec\n",
            "Epoch: [2], Test Loss: 0.5230, Accuracy: 0.71, Time: 4.61 sec\n",
            "\n",
            "\n",
            "Epoch: [3]/(200/461), Train Loss: 0.4071, Accuracy: 0.74, Time: 17.75 sec\n",
            "Epoch: [3]/(400/461), Train Loss: 0.3546, Accuracy: 0.75, Time: 35.28 sec\n",
            "Epoch: [3], Test Loss: 0.4565, Accuracy: 0.77, Time: 4.72 sec\n",
            "\n",
            "\n",
            "Epoch: [4]/(200/461), Train Loss: 0.7061, Accuracy: 0.76, Time: 17.73 sec\n",
            "Epoch: [4]/(400/461), Train Loss: 0.6272, Accuracy: 0.77, Time: 35.19 sec\n",
            "Epoch: [4], Test Loss: 0.4470, Accuracy: 0.77, Time: 4.64 sec\n",
            "\n",
            "\n",
            "Epoch: [5]/(200/461), Train Loss: 0.4971, Accuracy: 0.79, Time: 18.22 sec\n",
            "Epoch: [5]/(400/461), Train Loss: 0.5046, Accuracy: 0.79, Time: 35.63 sec\n",
            "Epoch: [5], Test Loss: 0.4632, Accuracy: 0.76, Time: 4.70 sec\n",
            "\n",
            "\n",
            "Epoch: [6]/(200/461), Train Loss: 0.2679, Accuracy: 0.81, Time: 17.79 sec\n",
            "Epoch: [6]/(400/461), Train Loss: 0.4643, Accuracy: 0.80, Time: 35.08 sec\n",
            "Epoch: [6], Test Loss: 0.4320, Accuracy: 0.79, Time: 4.67 sec\n",
            "\n",
            "\n",
            "Epoch: [7]/(200/461), Train Loss: 0.2909, Accuracy: 0.81, Time: 17.88 sec\n",
            "Epoch: [7]/(400/461), Train Loss: 0.3078, Accuracy: 0.81, Time: 35.50 sec\n",
            "Epoch: [7], Test Loss: 0.3961, Accuracy: 0.82, Time: 4.69 sec\n",
            "\n",
            "\n",
            "Epoch: [8]/(200/461), Train Loss: 0.3617, Accuracy: 0.82, Time: 17.38 sec\n",
            "Epoch: [8]/(400/461), Train Loss: 0.4951, Accuracy: 0.82, Time: 35.16 sec\n",
            "Epoch: [8], Test Loss: 0.3860, Accuracy: 0.82, Time: 4.60 sec\n",
            "\n",
            "\n",
            "Epoch: [9]/(200/461), Train Loss: 0.3944, Accuracy: 0.81, Time: 18.14 sec\n",
            "Epoch: [9]/(400/461), Train Loss: 0.2815, Accuracy: 0.82, Time: 35.49 sec\n",
            "Epoch: [9], Test Loss: 0.3742, Accuracy: 0.83, Time: 4.64 sec\n",
            "\n",
            "\n",
            "Epoch: [10]/(200/461), Train Loss: 0.4950, Accuracy: 0.84, Time: 17.68 sec\n",
            "Epoch: [10]/(400/461), Train Loss: 0.3647, Accuracy: 0.83, Time: 35.26 sec\n",
            "Epoch: [10], Test Loss: 0.3509, Accuracy: 0.85, Time: 4.74 sec\n",
            "\n",
            "\n",
            "Epoch: [11]/(200/461), Train Loss: 0.4647, Accuracy: 0.84, Time: 17.80 sec\n",
            "Epoch: [11]/(400/461), Train Loss: 0.2783, Accuracy: 0.83, Time: 35.01 sec\n",
            "Epoch: [11], Test Loss: 0.3805, Accuracy: 0.82, Time: 4.75 sec\n",
            "\n",
            "\n",
            "Epoch: [12]/(200/461), Train Loss: 0.5407, Accuracy: 0.84, Time: 17.57 sec\n",
            "Epoch: [12]/(400/461), Train Loss: 0.3983, Accuracy: 0.84, Time: 35.16 sec\n",
            "Epoch: [12], Test Loss: 0.3503, Accuracy: 0.84, Time: 4.67 sec\n",
            "\n",
            "\n",
            "Epoch: [13]/(200/461), Train Loss: 0.2675, Accuracy: 0.84, Time: 18.42 sec\n",
            "Epoch: [13]/(400/461), Train Loss: 0.3610, Accuracy: 0.84, Time: 35.69 sec\n",
            "Epoch: [13], Test Loss: 0.3405, Accuracy: 0.85, Time: 4.69 sec\n",
            "\n",
            "\n",
            "Epoch: [14]/(200/461), Train Loss: 0.4580, Accuracy: 0.85, Time: 17.77 sec\n",
            "Epoch: [14]/(400/461), Train Loss: 0.3072, Accuracy: 0.85, Time: 35.28 sec\n",
            "Epoch: [14], Test Loss: 0.3467, Accuracy: 0.83, Time: 4.72 sec\n",
            "\n",
            "\n",
            "Epoch: [15]/(200/461), Train Loss: 0.6085, Accuracy: 0.85, Time: 17.71 sec\n",
            "Epoch: [15]/(400/461), Train Loss: 0.2276, Accuracy: 0.85, Time: 35.23 sec\n",
            "Epoch: [15], Test Loss: 0.3225, Accuracy: 0.85, Time: 4.77 sec\n",
            "\n",
            "\n",
            "Epoch: [16]/(200/461), Train Loss: 0.3802, Accuracy: 0.86, Time: 18.14 sec\n",
            "Epoch: [16]/(400/461), Train Loss: 0.1209, Accuracy: 0.86, Time: 35.60 sec\n",
            "Epoch: [16], Test Loss: 0.3054, Accuracy: 0.86, Time: 4.68 sec\n",
            "\n",
            "\n",
            "Epoch: [17]/(200/461), Train Loss: 0.2272, Accuracy: 0.87, Time: 17.92 sec\n",
            "Epoch: [17]/(400/461), Train Loss: 0.3170, Accuracy: 0.86, Time: 35.65 sec\n",
            "Epoch: [17], Test Loss: 0.3185, Accuracy: 0.86, Time: 4.75 sec\n",
            "\n",
            "\n",
            "Epoch: [18]/(200/461), Train Loss: 0.1951, Accuracy: 0.87, Time: 17.91 sec\n",
            "Epoch: [18]/(400/461), Train Loss: 0.2521, Accuracy: 0.87, Time: 35.02 sec\n",
            "Epoch: [18], Test Loss: 0.2972, Accuracy: 0.87, Time: 4.68 sec\n",
            "\n",
            "\n",
            "Epoch: [19]/(200/461), Train Loss: 0.2231, Accuracy: 0.86, Time: 17.91 sec\n",
            "Epoch: [19]/(400/461), Train Loss: 0.4111, Accuracy: 0.86, Time: 35.27 sec\n",
            "Epoch: [19], Test Loss: 0.2982, Accuracy: 0.86, Time: 4.75 sec\n",
            "\n",
            "\n",
            "Epoch: [20]/(200/461), Train Loss: 0.0755, Accuracy: 0.88, Time: 17.86 sec\n",
            "Epoch: [20]/(400/461), Train Loss: 0.3074, Accuracy: 0.87, Time: 35.18 sec\n",
            "Epoch: [20], Test Loss: 0.2724, Accuracy: 0.89, Time: 4.72 sec\n",
            "\n",
            "\n",
            "Epoch: [21]/(200/461), Train Loss: 0.5063, Accuracy: 0.88, Time: 17.58 sec\n",
            "Epoch: [21]/(400/461), Train Loss: 0.4473, Accuracy: 0.88, Time: 35.39 sec\n",
            "Epoch: [21], Test Loss: 0.2669, Accuracy: 0.89, Time: 4.72 sec\n",
            "\n",
            "\n",
            "Epoch: [22]/(200/461), Train Loss: 0.3319, Accuracy: 0.88, Time: 18.24 sec\n",
            "Epoch: [22]/(400/461), Train Loss: 0.3255, Accuracy: 0.88, Time: 35.28 sec\n",
            "Epoch: [22], Test Loss: 0.2957, Accuracy: 0.87, Time: 4.79 sec\n",
            "\n",
            "\n",
            "Epoch: [23]/(200/461), Train Loss: 0.2594, Accuracy: 0.88, Time: 18.08 sec\n",
            "Epoch: [23]/(400/461), Train Loss: 0.5466, Accuracy: 0.88, Time: 35.78 sec\n",
            "Epoch: [23], Test Loss: 0.2591, Accuracy: 0.90, Time: 4.74 sec\n",
            "\n",
            "\n",
            "Epoch: [24]/(200/461), Train Loss: 0.7905, Accuracy: 0.88, Time: 17.76 sec\n",
            "Epoch: [24]/(400/461), Train Loss: 0.3264, Accuracy: 0.88, Time: 35.00 sec\n",
            "Epoch: [24], Test Loss: 0.2599, Accuracy: 0.89, Time: 4.71 sec\n",
            "\n",
            "\n",
            "Epoch: [25]/(200/461), Train Loss: 0.3739, Accuracy: 0.89, Time: 17.90 sec\n",
            "Epoch: [25]/(400/461), Train Loss: 0.4918, Accuracy: 0.89, Time: 35.26 sec\n",
            "Epoch: [25], Test Loss: 0.2488, Accuracy: 0.89, Time: 4.70 sec\n",
            "\n",
            "\n",
            "Epoch: [26]/(200/461), Train Loss: 0.4478, Accuracy: 0.90, Time: 17.74 sec\n",
            "Epoch: [26]/(400/461), Train Loss: 0.2457, Accuracy: 0.89, Time: 35.14 sec\n",
            "Epoch: [26], Test Loss: 0.2518, Accuracy: 0.90, Time: 4.82 sec\n",
            "\n",
            "\n",
            "Epoch: [27]/(200/461), Train Loss: 0.0733, Accuracy: 0.89, Time: 18.05 sec\n",
            "Epoch: [27]/(400/461), Train Loss: 0.4572, Accuracy: 0.89, Time: 35.35 sec\n",
            "Epoch: [27], Test Loss: 0.2576, Accuracy: 0.89, Time: 4.71 sec\n",
            "\n",
            "\n",
            "Epoch: [28]/(200/461), Train Loss: 0.1635, Accuracy: 0.90, Time: 17.95 sec\n",
            "Epoch: [28]/(400/461), Train Loss: 0.1784, Accuracy: 0.89, Time: 35.56 sec\n",
            "Epoch: [28], Test Loss: 0.2512, Accuracy: 0.89, Time: 4.68 sec\n",
            "\n",
            "\n",
            "Epoch: [29]/(200/461), Train Loss: 0.1908, Accuracy: 0.89, Time: 17.97 sec\n",
            "Epoch: [29]/(400/461), Train Loss: 0.1087, Accuracy: 0.89, Time: 35.78 sec\n",
            "Epoch: [29], Test Loss: 0.2266, Accuracy: 0.91, Time: 4.78 sec\n",
            "\n",
            "\n",
            "Epoch: [30]/(200/461), Train Loss: 0.2443, Accuracy: 0.90, Time: 17.80 sec\n",
            "Epoch: [30]/(400/461), Train Loss: 0.3378, Accuracy: 0.90, Time: 35.79 sec\n",
            "Epoch: [30], Test Loss: 0.2744, Accuracy: 0.88, Time: 4.78 sec\n",
            "\n",
            "\n",
            "Epoch: [31]/(200/461), Train Loss: 0.2895, Accuracy: 0.90, Time: 17.80 sec\n",
            "Epoch: [31]/(400/461), Train Loss: 0.1723, Accuracy: 0.90, Time: 35.73 sec\n",
            "Epoch: [31], Test Loss: 0.2630, Accuracy: 0.89, Time: 4.59 sec\n",
            "\n",
            "\n",
            "Epoch: [32]/(200/461), Train Loss: 0.1573, Accuracy: 0.90, Time: 18.01 sec\n",
            "Epoch: [32]/(400/461), Train Loss: 0.4146, Accuracy: 0.90, Time: 35.41 sec\n",
            "Epoch: [32], Test Loss: 0.2298, Accuracy: 0.91, Time: 4.73 sec\n",
            "\n",
            "\n",
            "Epoch: [33]/(200/461), Train Loss: 0.3472, Accuracy: 0.91, Time: 17.78 sec\n",
            "Epoch: [33]/(400/461), Train Loss: 0.1685, Accuracy: 0.90, Time: 35.69 sec\n",
            "Epoch: [33], Test Loss: 0.2339, Accuracy: 0.90, Time: 4.74 sec\n",
            "\n",
            "\n",
            "Epoch: [34]/(200/461), Train Loss: 0.2875, Accuracy: 0.90, Time: 18.00 sec\n",
            "Epoch: [34]/(400/461), Train Loss: 0.1668, Accuracy: 0.90, Time: 35.54 sec\n",
            "Epoch: [34], Test Loss: 0.2420, Accuracy: 0.89, Time: 4.68 sec\n",
            "\n",
            "\n",
            "Epoch: [35]/(200/461), Train Loss: 0.2038, Accuracy: 0.91, Time: 18.01 sec\n",
            "Epoch: [35]/(400/461), Train Loss: 0.2920, Accuracy: 0.91, Time: 35.39 sec\n",
            "Epoch: [35], Test Loss: 0.2303, Accuracy: 0.90, Time: 4.79 sec\n",
            "\n",
            "\n",
            "Epoch: [36]/(200/461), Train Loss: 0.2442, Accuracy: 0.91, Time: 17.96 sec\n",
            "Epoch: [36]/(400/461), Train Loss: 0.1508, Accuracy: 0.91, Time: 35.41 sec\n",
            "Epoch: [36], Test Loss: 0.2349, Accuracy: 0.90, Time: 4.85 sec\n",
            "\n",
            "\n",
            "Epoch: [37]/(200/461), Train Loss: 0.1607, Accuracy: 0.91, Time: 18.33 sec\n",
            "Epoch: [37]/(400/461), Train Loss: 0.1410, Accuracy: 0.91, Time: 36.23 sec\n",
            "Epoch: [37], Test Loss: 0.2177, Accuracy: 0.92, Time: 4.86 sec\n",
            "\n",
            "\n",
            "Epoch: [38]/(200/461), Train Loss: 0.1632, Accuracy: 0.92, Time: 18.34 sec\n",
            "Epoch: [38]/(400/461), Train Loss: 0.1994, Accuracy: 0.91, Time: 35.92 sec\n",
            "Epoch: [38], Test Loss: 0.2145, Accuracy: 0.91, Time: 4.71 sec\n",
            "\n",
            "\n",
            "Epoch: [39]/(200/461), Train Loss: 0.5886, Accuracy: 0.91, Time: 18.11 sec\n",
            "Epoch: [39]/(400/461), Train Loss: 0.2764, Accuracy: 0.91, Time: 35.78 sec\n",
            "Epoch: [39], Test Loss: 0.2261, Accuracy: 0.91, Time: 4.76 sec\n",
            "\n",
            "\n",
            "Epoch: [40]/(200/461), Train Loss: 0.1612, Accuracy: 0.92, Time: 18.26 sec\n",
            "Epoch: [40]/(400/461), Train Loss: 0.1295, Accuracy: 0.92, Time: 36.13 sec\n",
            "Epoch: [40], Test Loss: 0.2241, Accuracy: 0.91, Time: 4.67 sec\n",
            "\n",
            "\n",
            "Epoch: [41]/(200/461), Train Loss: 0.2623, Accuracy: 0.91, Time: 17.84 sec\n",
            "Epoch: [41]/(400/461), Train Loss: 0.1885, Accuracy: 0.92, Time: 35.27 sec\n",
            "Epoch: [41], Test Loss: 0.1871, Accuracy: 0.93, Time: 4.76 sec\n",
            "\n",
            "\n",
            "Epoch: [42]/(200/461), Train Loss: 0.1653, Accuracy: 0.92, Time: 18.34 sec\n",
            "Epoch: [42]/(400/461), Train Loss: 0.3535, Accuracy: 0.92, Time: 35.87 sec\n",
            "Epoch: [42], Test Loss: 0.2064, Accuracy: 0.91, Time: 4.76 sec\n",
            "\n",
            "\n",
            "Epoch: [43]/(200/461), Train Loss: 0.0650, Accuracy: 0.91, Time: 17.67 sec\n",
            "Epoch: [43]/(400/461), Train Loss: 0.2822, Accuracy: 0.92, Time: 35.59 sec\n",
            "Epoch: [43], Test Loss: 0.2206, Accuracy: 0.91, Time: 4.76 sec\n",
            "\n",
            "\n",
            "Epoch: [44]/(200/461), Train Loss: 0.0308, Accuracy: 0.92, Time: 17.92 sec\n",
            "Epoch: [44]/(400/461), Train Loss: 0.1314, Accuracy: 0.92, Time: 35.38 sec\n",
            "Epoch: [44], Test Loss: 0.1997, Accuracy: 0.92, Time: 4.80 sec\n",
            "\n",
            "\n",
            "Epoch: [45]/(200/461), Train Loss: 0.3289, Accuracy: 0.93, Time: 18.22 sec\n",
            "Epoch: [45]/(400/461), Train Loss: 0.1498, Accuracy: 0.92, Time: 35.94 sec\n",
            "Epoch: [45], Test Loss: 0.1923, Accuracy: 0.93, Time: 4.67 sec\n",
            "\n",
            "\n",
            "Epoch: [46]/(200/461), Train Loss: 0.1833, Accuracy: 0.93, Time: 17.53 sec\n",
            "Epoch: [46]/(400/461), Train Loss: 0.0492, Accuracy: 0.93, Time: 35.48 sec\n",
            "Epoch: [46], Test Loss: 0.1722, Accuracy: 0.93, Time: 4.81 sec\n",
            "\n",
            "\n",
            "Epoch: [47]/(200/461), Train Loss: 0.1110, Accuracy: 0.93, Time: 18.08 sec\n",
            "Epoch: [47]/(400/461), Train Loss: 0.4347, Accuracy: 0.93, Time: 35.38 sec\n",
            "Epoch: [47], Test Loss: 0.1755, Accuracy: 0.94, Time: 4.71 sec\n",
            "\n",
            "\n",
            "Epoch: [48]/(200/461), Train Loss: 0.1468, Accuracy: 0.93, Time: 17.95 sec\n",
            "Epoch: [48]/(400/461), Train Loss: 0.1115, Accuracy: 0.93, Time: 35.40 sec\n",
            "Epoch: [48], Test Loss: 0.1795, Accuracy: 0.93, Time: 4.76 sec\n",
            "\n",
            "\n",
            "Epoch: [49]/(200/461), Train Loss: 0.3569, Accuracy: 0.93, Time: 17.79 sec\n",
            "Epoch: [49]/(400/461), Train Loss: 0.0724, Accuracy: 0.93, Time: 35.60 sec\n",
            "Epoch: [49], Test Loss: 0.1797, Accuracy: 0.93, Time: 4.70 sec\n",
            "\n",
            "\n",
            "Epoch: [50]/(200/461), Train Loss: 0.1792, Accuracy: 0.93, Time: 17.73 sec\n",
            "Epoch: [50]/(400/461), Train Loss: 0.1241, Accuracy: 0.93, Time: 35.59 sec\n",
            "Epoch: [50], Test Loss: 0.1791, Accuracy: 0.93, Time: 4.69 sec\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}