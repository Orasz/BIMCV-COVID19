{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRfC1qHyKx2+Y8TpoKwjzQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Orasz/CNN4COVID19/blob/main/scratchConfusionMatrixCG1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykovEOkLAwmY",
        "outputId": "0236e9ca-e2a9-422e-f74b-4a48f1ab8d5c"
      },
      "source": [
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)\r\n",
        "\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbBMqMVRA5zH",
        "outputId": "033b2325-10f4-4993-c5a4-d255f28c8d42"
      },
      "source": [
        "\r\n",
        "\r\n",
        "from __future__ import print_function, division\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import numpy as np\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, models, transforms\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n",
        "import os\r\n",
        "import copy\r\n",
        "from torchsummary import summary\r\n",
        "\r\n",
        "plt.ion()   # interactive mode\r\n",
        "print(\"done\")\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbotxk5LBJNw",
        "outputId": "e453e820-3375-490b-ecd5-fe2103911a7c"
      },
      "source": [
        "# Data augmentation and normalization for training\r\n",
        "# Just normalization for validation\r\n",
        "\r\n",
        "data_transforms_xray = {\r\n",
        "    'train': transforms.Compose([\r\n",
        "        transforms.Resize(256),\r\n",
        "        transforms.CenterCrop(256),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ]),\r\n",
        "    'val': transforms.Compose([\r\n",
        "        transforms.Resize(256),\r\n",
        "        transforms.CenterCrop(256),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ]),\r\n",
        "        'test': transforms.Compose([\r\n",
        "        transforms.Resize(256),\r\n",
        "        transforms.CenterCrop(256),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ])\r\n",
        "}\r\n",
        "\r\n",
        "data_dir = 'gdrive/MyDrive/datasetQaTa/'\r\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\r\n",
        "                                          data_transforms_xray[x])\r\n",
        "                  for x in ['train', 'val']}\r\n",
        "#aumenta batch size \r\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\r\n",
        "                                             shuffle=True, num_workers=4)\r\n",
        "              for x in ['train', 'val']}\r\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\r\n",
        "print(\"Dataset sizes: {}\".format(dataset_sizes))\r\n",
        "class_names = image_datasets['train'].classes\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(\"using device: {}\".format(device))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset sizes: {'train': 7375, 'val': 940}\n",
            "using device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-52PWHDBF4E",
        "outputId": "0240e389-c31f-4989-927e-89235f8bc0a2"
      },
      "source": [
        "class ScratchCNN(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(ScratchCNN, self).__init__()\r\n",
        "        \r\n",
        "        self.model = nn.Sequential(\r\n",
        "            nn.Conv2d(3, 16, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(16, 16, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2,2),\r\n",
        "\r\n",
        "            nn.Conv2d(16, 32, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(32, 32, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2,2),\r\n",
        "\r\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(64, 64, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2,2),\r\n",
        "\r\n",
        "            nn.Conv2d(64, 128, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(128, 128, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2,2),\r\n",
        "\r\n",
        "            nn.Conv2d(128, 256, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(256, 256, kernel_size=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(2,2),\r\n",
        "\r\n",
        "        ).to(device)\r\n",
        "        \r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            nn.Flatten(),\r\n",
        "            nn.Dropout(0.25),\r\n",
        "            nn.Linear(4096, 256),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout(0.25),\r\n",
        "            nn.Linear(256, 2)\r\n",
        "        ).to(device)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.model(x)\r\n",
        "        x = self.classifier(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "model = ScratchCNN().to(device)\r\n",
        "summary(model, (3,256,256))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 254, 254]             448\n",
            "              ReLU-2         [-1, 16, 254, 254]               0\n",
            "            Conv2d-3         [-1, 16, 252, 252]           2,320\n",
            "              ReLU-4         [-1, 16, 252, 252]               0\n",
            "         MaxPool2d-5         [-1, 16, 126, 126]               0\n",
            "            Conv2d-6         [-1, 32, 124, 124]           4,640\n",
            "              ReLU-7         [-1, 32, 124, 124]               0\n",
            "            Conv2d-8         [-1, 32, 122, 122]           9,248\n",
            "              ReLU-9         [-1, 32, 122, 122]               0\n",
            "        MaxPool2d-10           [-1, 32, 61, 61]               0\n",
            "           Conv2d-11           [-1, 64, 59, 59]          18,496\n",
            "             ReLU-12           [-1, 64, 59, 59]               0\n",
            "           Conv2d-13           [-1, 64, 57, 57]          36,928\n",
            "             ReLU-14           [-1, 64, 57, 57]               0\n",
            "        MaxPool2d-15           [-1, 64, 28, 28]               0\n",
            "           Conv2d-16          [-1, 128, 26, 26]          73,856\n",
            "             ReLU-17          [-1, 128, 26, 26]               0\n",
            "           Conv2d-18          [-1, 128, 24, 24]         147,584\n",
            "             ReLU-19          [-1, 128, 24, 24]               0\n",
            "        MaxPool2d-20          [-1, 128, 12, 12]               0\n",
            "           Conv2d-21          [-1, 256, 10, 10]         295,168\n",
            "             ReLU-22          [-1, 256, 10, 10]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-24            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-25            [-1, 256, 4, 4]               0\n",
            "          Flatten-26                 [-1, 4096]               0\n",
            "          Dropout-27                 [-1, 4096]               0\n",
            "           Linear-28                  [-1, 256]       1,048,832\n",
            "             ReLU-29                  [-1, 256]               0\n",
            "          Dropout-30                  [-1, 256]               0\n",
            "           Linear-31                    [-1, 2]             514\n",
            "================================================================\n",
            "Total params: 2,228,114\n",
            "Trainable params: 2,228,114\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 59.16\n",
            "Params size (MB): 8.50\n",
            "Estimated Total Size (MB): 68.41\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nh8iBF8CdcY"
      },
      "source": [
        "lr = 0.00001\r\n",
        "model = ScratchCNN().to(device)\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnaV0o3VCqcV"
      },
      "source": [
        "def Train(model, epoch, print_every=len(dataloaders['train'])):\r\n",
        "    total_loss = 0\r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    accuracy = []\r\n",
        "    \r\n",
        "    for i, batch in enumerate(dataloaders['train'], 1):\r\n",
        "        minput = batch[0].to(device) # Get batch of images from our train dataloader\r\n",
        "        target = batch[1].to(device) # Get the corresponding target(0, 1 or 2) representing cats, dogs or pandas\r\n",
        "        \r\n",
        "        moutput = model(minput) # output by our model\r\n",
        "        \r\n",
        "        loss = criterion(moutput, target) # compute cross entropy loss\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        optimizer.zero_grad() # Clear the gradients if exists. (Gradients are used for back-propogation.)\r\n",
        "        loss.backward() # Back propogate the losses\r\n",
        "        optimizer.step() # Update Model parameters\r\n",
        "        \r\n",
        "        argmax = moutput.argmax(dim=1) # Get the class index with maximum probability predicted by the model\r\n",
        "        accuracy.append((target==argmax).sum().item() / target.shape[0]) # calculate accuracy by comparing to target tensor\r\n",
        "\r\n",
        "        if i%print_every == 0:\r\n",
        "            print('Epoch: [{}]/({}/{}), Train Loss: {:.4f}, Accuracy: {:.2f}, Time: {:.2f} sec'.format(\r\n",
        "                epoch, i, len(dataloaders['train']), loss.item(), sum(accuracy)/len(accuracy), time.time()-start_time \r\n",
        "            ))\r\n",
        "    \r\n",
        "    return total_loss / len(dataloaders['train']) # Returning Average Training Loss"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKaLxh_4DKOh"
      },
      "source": [
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\r\n",
        "                                          data_transforms_xray[x])\r\n",
        "                  for x in ['train', 'val', 'test']}\r\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\r\n",
        "                                             shuffle=True, num_workers=4)\r\n",
        "              for x in ['train', 'val','test']}\r\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val','test']}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hikcw_TcZRah"
      },
      "source": [
        "def Test(model,epoch):\r\n",
        "    total_loss = 0\r\n",
        "    start_time = time.time()\r\n",
        "\r\n",
        "    accuracy = []\r\n",
        "    \r\n",
        "    with torch.no_grad(): # disable calculations of gradients for all pytorch operations inside the block\r\n",
        "        for i, batch in enumerate(dataloaders['test']):\r\n",
        "            minput = batch[0].to(device) # Get batch of images from our test dataloader\r\n",
        "            target = batch[1].to(device) # Get the corresponding target(0, 1 or 2) representing cats, dogs or pandas\r\n",
        "            moutput = model(minput) # output by our model\r\n",
        "\r\n",
        "            loss = criterion(moutput, target) # compute cross entropy loss\r\n",
        "            total_loss += loss.item()\r\n",
        "            \r\n",
        "            \r\n",
        "            # To get the probabilities for different classes we need to apply a softmax operation on moutput \r\n",
        "            argmax = moutput.argmax(dim=1) # Find the index(0, 1 or 2) with maximum score (which denotes class with maximum probability)\r\n",
        "            accuracy.append((target==argmax).sum().item() / target.shape[0]) # Find the accuracy of the batch by comparing it with actual targets\r\n",
        "            \r\n",
        "    print('Epoch: [{}], Test Loss: {:.4f}, Accuracy: {:.2f}, Time: {:.2f} sec'.format(\r\n",
        "        epoch, total_loss/len(dataloaders['test']), sum(accuracy)/len(accuracy), time.time()-start_time\r\n",
        "    ))\r\n",
        "    return total_loss/len(dataloaders['test']) # Returning Average Testing Loss"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM9AqOR0Dyc0",
        "outputId": "70ae77fd-e227-4262-ddf3-38f8c8859fe7"
      },
      "source": [
        "\r\n",
        "Test(model,0)\r\n",
        "\r\n",
        "train_loss = []\r\n",
        "test_loss = []\r\n",
        "\r\n",
        "for epoch in range(1, 51):\r\n",
        "    train_loss.append(Train(model,epoch,200))\r\n",
        "    test_loss.append(Test(model,epoch))\r\n",
        "\r\n",
        "    print('\\n')\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0], Test Loss: 0.6932, Accuracy: 0.50, Time: 115.07 sec\n",
            "Epoch: [1]/(200/461), Train Loss: 0.6935, Accuracy: 0.50, Time: 372.20 sec\n",
            "Epoch: [1]/(400/461), Train Loss: 0.6938, Accuracy: 0.51, Time: 720.67 sec\n",
            "Epoch: [1], Test Loss: 0.6923, Accuracy: 0.50, Time: 4.47 sec\n",
            "\n",
            "\n",
            "Epoch: [2]/(200/461), Train Loss: 0.4892, Accuracy: 0.64, Time: 16.92 sec\n",
            "Epoch: [2]/(400/461), Train Loss: 0.6324, Accuracy: 0.68, Time: 32.97 sec\n",
            "Epoch: [2], Test Loss: 0.5178, Accuracy: 0.71, Time: 4.49 sec\n",
            "\n",
            "\n",
            "Epoch: [3]/(200/461), Train Loss: 0.5086, Accuracy: 0.74, Time: 16.37 sec\n",
            "Epoch: [3]/(400/461), Train Loss: 0.4451, Accuracy: 0.75, Time: 32.87 sec\n",
            "Epoch: [3], Test Loss: 0.4884, Accuracy: 0.73, Time: 4.43 sec\n",
            "\n",
            "\n",
            "Epoch: [4]/(200/461), Train Loss: 0.3836, Accuracy: 0.77, Time: 16.71 sec\n",
            "Epoch: [4]/(400/461), Train Loss: 0.4504, Accuracy: 0.77, Time: 32.95 sec\n",
            "Epoch: [4], Test Loss: 0.4484, Accuracy: 0.77, Time: 4.53 sec\n",
            "\n",
            "\n",
            "Epoch: [5]/(200/461), Train Loss: 0.7639, Accuracy: 0.79, Time: 16.83 sec\n",
            "Epoch: [5]/(400/461), Train Loss: 0.6114, Accuracy: 0.79, Time: 32.89 sec\n",
            "Epoch: [5], Test Loss: 0.4226, Accuracy: 0.79, Time: 4.44 sec\n",
            "\n",
            "\n",
            "Epoch: [6]/(200/461), Train Loss: 0.4497, Accuracy: 0.82, Time: 16.77 sec\n",
            "Epoch: [6]/(400/461), Train Loss: 0.4290, Accuracy: 0.81, Time: 33.30 sec\n",
            "Epoch: [6], Test Loss: 0.3928, Accuracy: 0.82, Time: 4.43 sec\n",
            "\n",
            "\n",
            "Epoch: [7]/(200/461), Train Loss: 0.5109, Accuracy: 0.81, Time: 16.66 sec\n",
            "Epoch: [7]/(400/461), Train Loss: 0.5043, Accuracy: 0.81, Time: 33.02 sec\n",
            "Epoch: [7], Test Loss: 0.3885, Accuracy: 0.81, Time: 4.50 sec\n",
            "\n",
            "\n",
            "Epoch: [8]/(200/461), Train Loss: 0.2781, Accuracy: 0.82, Time: 16.88 sec\n",
            "Epoch: [8]/(400/461), Train Loss: 0.2190, Accuracy: 0.82, Time: 33.05 sec\n",
            "Epoch: [8], Test Loss: 0.3807, Accuracy: 0.83, Time: 4.45 sec\n",
            "\n",
            "\n",
            "Epoch: [9]/(200/461), Train Loss: 0.3745, Accuracy: 0.83, Time: 16.64 sec\n",
            "Epoch: [9]/(400/461), Train Loss: 0.4422, Accuracy: 0.84, Time: 33.07 sec\n",
            "Epoch: [9], Test Loss: 0.3559, Accuracy: 0.85, Time: 4.46 sec\n",
            "\n",
            "\n",
            "Epoch: [10]/(200/461), Train Loss: 0.2491, Accuracy: 0.85, Time: 16.46 sec\n",
            "Epoch: [10]/(400/461), Train Loss: 0.5090, Accuracy: 0.84, Time: 33.53 sec\n",
            "Epoch: [10], Test Loss: 0.3344, Accuracy: 0.86, Time: 4.78 sec\n",
            "\n",
            "\n",
            "Epoch: [11]/(200/461), Train Loss: 0.4946, Accuracy: 0.85, Time: 16.97 sec\n",
            "Epoch: [11]/(400/461), Train Loss: 0.2751, Accuracy: 0.85, Time: 34.39 sec\n",
            "Epoch: [11], Test Loss: 0.3055, Accuracy: 0.87, Time: 4.59 sec\n",
            "\n",
            "\n",
            "Epoch: [12]/(200/461), Train Loss: 0.1486, Accuracy: 0.85, Time: 17.35 sec\n",
            "Epoch: [12]/(400/461), Train Loss: 0.2295, Accuracy: 0.85, Time: 33.97 sec\n",
            "Epoch: [12], Test Loss: 0.3033, Accuracy: 0.87, Time: 4.49 sec\n",
            "\n",
            "\n",
            "Epoch: [13]/(200/461), Train Loss: 0.6862, Accuracy: 0.86, Time: 17.24 sec\n",
            "Epoch: [13]/(400/461), Train Loss: 0.1703, Accuracy: 0.86, Time: 34.19 sec\n",
            "Epoch: [13], Test Loss: 0.2914, Accuracy: 0.88, Time: 4.49 sec\n",
            "\n",
            "\n",
            "Epoch: [14]/(200/461), Train Loss: 0.6718, Accuracy: 0.86, Time: 16.90 sec\n",
            "Epoch: [14]/(400/461), Train Loss: 0.4033, Accuracy: 0.86, Time: 33.74 sec\n",
            "Epoch: [14], Test Loss: 0.2895, Accuracy: 0.89, Time: 4.55 sec\n",
            "\n",
            "\n",
            "Epoch: [15]/(200/461), Train Loss: 0.2168, Accuracy: 0.87, Time: 16.60 sec\n",
            "Epoch: [15]/(400/461), Train Loss: 0.1448, Accuracy: 0.86, Time: 33.56 sec\n",
            "Epoch: [15], Test Loss: 0.2900, Accuracy: 0.89, Time: 4.51 sec\n",
            "\n",
            "\n",
            "Epoch: [16]/(200/461), Train Loss: 0.4742, Accuracy: 0.88, Time: 16.72 sec\n",
            "Epoch: [16]/(400/461), Train Loss: 0.4592, Accuracy: 0.87, Time: 33.36 sec\n",
            "Epoch: [16], Test Loss: 0.2620, Accuracy: 0.90, Time: 4.48 sec\n",
            "\n",
            "\n",
            "Epoch: [17]/(200/461), Train Loss: 0.3063, Accuracy: 0.87, Time: 17.07 sec\n",
            "Epoch: [17]/(400/461), Train Loss: 0.3731, Accuracy: 0.88, Time: 33.58 sec\n",
            "Epoch: [17], Test Loss: 0.2828, Accuracy: 0.87, Time: 4.55 sec\n",
            "\n",
            "\n",
            "Epoch: [18]/(200/461), Train Loss: 0.1661, Accuracy: 0.88, Time: 17.36 sec\n",
            "Epoch: [18]/(400/461), Train Loss: 0.4581, Accuracy: 0.88, Time: 34.11 sec\n",
            "Epoch: [18], Test Loss: 0.2548, Accuracy: 0.90, Time: 4.62 sec\n",
            "\n",
            "\n",
            "Epoch: [19]/(200/461), Train Loss: 0.2588, Accuracy: 0.88, Time: 16.94 sec\n",
            "Epoch: [19]/(400/461), Train Loss: 0.1717, Accuracy: 0.88, Time: 33.74 sec\n",
            "Epoch: [19], Test Loss: 0.2697, Accuracy: 0.89, Time: 4.50 sec\n",
            "\n",
            "\n",
            "Epoch: [20]/(200/461), Train Loss: 0.4373, Accuracy: 0.89, Time: 17.16 sec\n",
            "Epoch: [20]/(400/461), Train Loss: 0.5900, Accuracy: 0.89, Time: 33.91 sec\n",
            "Epoch: [20], Test Loss: 0.2386, Accuracy: 0.91, Time: 4.69 sec\n",
            "\n",
            "\n",
            "Epoch: [21]/(200/461), Train Loss: 0.2444, Accuracy: 0.89, Time: 17.00 sec\n",
            "Epoch: [21]/(400/461), Train Loss: 0.1706, Accuracy: 0.89, Time: 33.68 sec\n",
            "Epoch: [21], Test Loss: 0.2729, Accuracy: 0.88, Time: 4.57 sec\n",
            "\n",
            "\n",
            "Epoch: [22]/(200/461), Train Loss: 0.2454, Accuracy: 0.89, Time: 17.20 sec\n",
            "Epoch: [22]/(400/461), Train Loss: 0.2154, Accuracy: 0.90, Time: 33.97 sec\n",
            "Epoch: [22], Test Loss: 0.2507, Accuracy: 0.89, Time: 4.58 sec\n",
            "\n",
            "\n",
            "Epoch: [23]/(200/461), Train Loss: 0.1192, Accuracy: 0.89, Time: 16.98 sec\n",
            "Epoch: [23]/(400/461), Train Loss: 0.3917, Accuracy: 0.89, Time: 33.61 sec\n",
            "Epoch: [23], Test Loss: 0.2283, Accuracy: 0.90, Time: 4.53 sec\n",
            "\n",
            "\n",
            "Epoch: [24]/(200/461), Train Loss: 0.2948, Accuracy: 0.90, Time: 17.05 sec\n",
            "Epoch: [24]/(400/461), Train Loss: 0.2751, Accuracy: 0.90, Time: 33.46 sec\n",
            "Epoch: [24], Test Loss: 0.2647, Accuracy: 0.88, Time: 4.54 sec\n",
            "\n",
            "\n",
            "Epoch: [25]/(200/461), Train Loss: 0.2165, Accuracy: 0.90, Time: 16.80 sec\n",
            "Epoch: [25]/(400/461), Train Loss: 0.2686, Accuracy: 0.90, Time: 33.26 sec\n",
            "Epoch: [25], Test Loss: 0.2502, Accuracy: 0.90, Time: 4.47 sec\n",
            "\n",
            "\n",
            "Epoch: [26]/(200/461), Train Loss: 0.1265, Accuracy: 0.90, Time: 16.76 sec\n",
            "Epoch: [26]/(400/461), Train Loss: 0.1430, Accuracy: 0.90, Time: 33.54 sec\n",
            "Epoch: [26], Test Loss: 0.2399, Accuracy: 0.90, Time: 4.47 sec\n",
            "\n",
            "\n",
            "Epoch: [27]/(200/461), Train Loss: 0.0874, Accuracy: 0.91, Time: 16.93 sec\n",
            "Epoch: [27]/(400/461), Train Loss: 0.2721, Accuracy: 0.90, Time: 33.33 sec\n",
            "Epoch: [27], Test Loss: 0.2281, Accuracy: 0.90, Time: 4.65 sec\n",
            "\n",
            "\n",
            "Epoch: [28]/(200/461), Train Loss: 0.4723, Accuracy: 0.90, Time: 17.30 sec\n",
            "Epoch: [28]/(400/461), Train Loss: 0.2343, Accuracy: 0.91, Time: 34.24 sec\n",
            "Epoch: [28], Test Loss: 0.2055, Accuracy: 0.92, Time: 4.60 sec\n",
            "\n",
            "\n",
            "Epoch: [29]/(200/461), Train Loss: 0.3072, Accuracy: 0.90, Time: 17.10 sec\n",
            "Epoch: [29]/(400/461), Train Loss: 0.2655, Accuracy: 0.91, Time: 33.71 sec\n",
            "Epoch: [29], Test Loss: 0.2156, Accuracy: 0.92, Time: 4.44 sec\n",
            "\n",
            "\n",
            "Epoch: [30]/(200/461), Train Loss: 0.2333, Accuracy: 0.91, Time: 17.00 sec\n",
            "Epoch: [30]/(400/461), Train Loss: 0.1656, Accuracy: 0.91, Time: 33.41 sec\n",
            "Epoch: [30], Test Loss: 0.2134, Accuracy: 0.92, Time: 4.48 sec\n",
            "\n",
            "\n",
            "Epoch: [31]/(200/461), Train Loss: 0.0774, Accuracy: 0.90, Time: 17.03 sec\n",
            "Epoch: [31]/(400/461), Train Loss: 0.0865, Accuracy: 0.91, Time: 33.53 sec\n",
            "Epoch: [31], Test Loss: 0.2129, Accuracy: 0.91, Time: 4.49 sec\n",
            "\n",
            "\n",
            "Epoch: [32]/(200/461), Train Loss: 0.1922, Accuracy: 0.92, Time: 16.72 sec\n",
            "Epoch: [32]/(400/461), Train Loss: 0.3286, Accuracy: 0.91, Time: 33.63 sec\n",
            "Epoch: [32], Test Loss: 0.2199, Accuracy: 0.92, Time: 4.52 sec\n",
            "\n",
            "\n",
            "Epoch: [33]/(200/461), Train Loss: 0.1303, Accuracy: 0.92, Time: 17.15 sec\n",
            "Epoch: [33]/(400/461), Train Loss: 0.2012, Accuracy: 0.92, Time: 33.45 sec\n",
            "Epoch: [33], Test Loss: 0.2008, Accuracy: 0.92, Time: 4.53 sec\n",
            "\n",
            "\n",
            "Epoch: [34]/(200/461), Train Loss: 0.4273, Accuracy: 0.92, Time: 16.93 sec\n",
            "Epoch: [34]/(400/461), Train Loss: 0.1138, Accuracy: 0.92, Time: 33.67 sec\n",
            "Epoch: [34], Test Loss: 0.2048, Accuracy: 0.92, Time: 4.62 sec\n",
            "\n",
            "\n",
            "Epoch: [35]/(200/461), Train Loss: 0.5179, Accuracy: 0.91, Time: 17.33 sec\n",
            "Epoch: [35]/(400/461), Train Loss: 0.0687, Accuracy: 0.92, Time: 34.17 sec\n",
            "Epoch: [35], Test Loss: 0.1992, Accuracy: 0.92, Time: 4.72 sec\n",
            "\n",
            "\n",
            "Epoch: [36]/(200/461), Train Loss: 0.2989, Accuracy: 0.92, Time: 17.62 sec\n",
            "Epoch: [36]/(400/461), Train Loss: 0.1231, Accuracy: 0.92, Time: 34.60 sec\n",
            "Epoch: [36], Test Loss: 0.1849, Accuracy: 0.93, Time: 4.58 sec\n",
            "\n",
            "\n",
            "Epoch: [37]/(200/461), Train Loss: 0.6005, Accuracy: 0.92, Time: 16.99 sec\n",
            "Epoch: [37]/(400/461), Train Loss: 0.2577, Accuracy: 0.92, Time: 33.98 sec\n",
            "Epoch: [37], Test Loss: 0.1958, Accuracy: 0.92, Time: 4.66 sec\n",
            "\n",
            "\n",
            "Epoch: [38]/(200/461), Train Loss: 0.2704, Accuracy: 0.92, Time: 17.23 sec\n",
            "Epoch: [38]/(400/461), Train Loss: 0.4132, Accuracy: 0.92, Time: 34.00 sec\n",
            "Epoch: [38], Test Loss: 0.1930, Accuracy: 0.92, Time: 4.56 sec\n",
            "\n",
            "\n",
            "Epoch: [39]/(200/461), Train Loss: 0.0994, Accuracy: 0.92, Time: 16.94 sec\n",
            "Epoch: [39]/(400/461), Train Loss: 0.1429, Accuracy: 0.92, Time: 33.63 sec\n",
            "Epoch: [39], Test Loss: 0.1900, Accuracy: 0.93, Time: 4.59 sec\n",
            "\n",
            "\n",
            "Epoch: [40]/(200/461), Train Loss: 0.3881, Accuracy: 0.92, Time: 17.56 sec\n",
            "Epoch: [40]/(400/461), Train Loss: 0.1395, Accuracy: 0.92, Time: 33.84 sec\n",
            "Epoch: [40], Test Loss: 0.1889, Accuracy: 0.94, Time: 4.59 sec\n",
            "\n",
            "\n",
            "Epoch: [41]/(200/461), Train Loss: 0.1051, Accuracy: 0.93, Time: 16.70 sec\n",
            "Epoch: [41]/(400/461), Train Loss: 0.2850, Accuracy: 0.93, Time: 33.36 sec\n",
            "Epoch: [41], Test Loss: 0.1894, Accuracy: 0.92, Time: 4.58 sec\n",
            "\n",
            "\n",
            "Epoch: [42]/(200/461), Train Loss: 0.0484, Accuracy: 0.93, Time: 17.22 sec\n",
            "Epoch: [42]/(400/461), Train Loss: 0.2516, Accuracy: 0.93, Time: 34.26 sec\n",
            "Epoch: [42], Test Loss: 0.1652, Accuracy: 0.94, Time: 4.53 sec\n",
            "\n",
            "\n",
            "Epoch: [43]/(200/461), Train Loss: 0.0512, Accuracy: 0.94, Time: 16.90 sec\n",
            "Epoch: [43]/(400/461), Train Loss: 0.2708, Accuracy: 0.93, Time: 33.69 sec\n",
            "Epoch: [43], Test Loss: 0.1771, Accuracy: 0.93, Time: 4.56 sec\n",
            "\n",
            "\n",
            "Epoch: [44]/(200/461), Train Loss: 0.1651, Accuracy: 0.93, Time: 16.87 sec\n",
            "Epoch: [44]/(400/461), Train Loss: 0.1010, Accuracy: 0.93, Time: 33.75 sec\n",
            "Epoch: [44], Test Loss: 0.1871, Accuracy: 0.93, Time: 4.58 sec\n",
            "\n",
            "\n",
            "Epoch: [45]/(200/461), Train Loss: 0.0549, Accuracy: 0.93, Time: 16.97 sec\n",
            "Epoch: [45]/(400/461), Train Loss: 0.2981, Accuracy: 0.93, Time: 33.69 sec\n",
            "Epoch: [45], Test Loss: 0.1933, Accuracy: 0.93, Time: 4.54 sec\n",
            "\n",
            "\n",
            "Epoch: [46]/(200/461), Train Loss: 0.1073, Accuracy: 0.94, Time: 16.88 sec\n",
            "Epoch: [46]/(400/461), Train Loss: 0.1530, Accuracy: 0.94, Time: 33.51 sec\n",
            "Epoch: [46], Test Loss: 0.1736, Accuracy: 0.93, Time: 4.55 sec\n",
            "\n",
            "\n",
            "Epoch: [47]/(200/461), Train Loss: 0.1378, Accuracy: 0.93, Time: 17.37 sec\n",
            "Epoch: [47]/(400/461), Train Loss: 0.0372, Accuracy: 0.93, Time: 33.80 sec\n",
            "Epoch: [47], Test Loss: 0.1994, Accuracy: 0.92, Time: 4.52 sec\n",
            "\n",
            "\n",
            "Epoch: [48]/(200/461), Train Loss: 0.0571, Accuracy: 0.95, Time: 16.98 sec\n",
            "Epoch: [48]/(400/461), Train Loss: 0.0639, Accuracy: 0.94, Time: 33.43 sec\n",
            "Epoch: [48], Test Loss: 0.1809, Accuracy: 0.93, Time: 4.52 sec\n",
            "\n",
            "\n",
            "Epoch: [49]/(200/461), Train Loss: 0.0829, Accuracy: 0.94, Time: 17.11 sec\n",
            "Epoch: [49]/(400/461), Train Loss: 0.0416, Accuracy: 0.94, Time: 34.03 sec\n",
            "Epoch: [49], Test Loss: 0.1868, Accuracy: 0.93, Time: 4.53 sec\n",
            "\n",
            "\n",
            "Epoch: [50]/(200/461), Train Loss: 0.0318, Accuracy: 0.95, Time: 17.00 sec\n",
            "Epoch: [50]/(400/461), Train Loss: 0.2786, Accuracy: 0.94, Time: 33.60 sec\n",
            "Epoch: [50], Test Loss: 0.1806, Accuracy: 0.93, Time: 4.54 sec\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SUk4UFwxD1C"
      },
      "source": [
        "\r\n",
        "def printcm(model):\r\n",
        "  confusion_matrixx = torch.zeros(2, 2)\r\n",
        "  with torch.no_grad():\r\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['test']):\r\n",
        "        inputs = inputs.to(device)\r\n",
        "        classes = classes.to(device)\r\n",
        "        outputs = model(inputs)\r\n",
        "        _, preds = torch.max(outputs, 1)\r\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\r\n",
        "                confusion_matrixx[t.long(), p.long()] += 1\r\n",
        "\r\n",
        "  print(confusion_matrixx)\r\n",
        "  return confusion_matrixx\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U5DdAvhxIjm",
        "outputId": "a01a096f-b667-418b-a2ec-c6b25f9df2f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cm = printcm(model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[417.,  39.],\n",
            "        [ 25., 431.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgCyqx84xVTd"
      },
      "source": [
        "import itertools\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\r\n",
        "    if normalize:\r\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
        "        print(\"Normalized confusion matrix\")\r\n",
        "    else:\r\n",
        "        print('Confusion matrix, without normalization')\r\n",
        "\r\n",
        "    print(cm)\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "    plt.title(title)\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
        "    plt.yticks(tick_marks, classes)\r\n",
        "\r\n",
        "    fmt = '.2f'\r\n",
        "    thresh = cm.max() / 2.\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('True label')\r\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUE_98hbxXZN",
        "outputId": "09f20c78-8d1e-462e-b0a8-da438c5a03ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "source": [
        "plt.figure(figsize=(8,8))\r\n",
        "plot_confusion_matrix(cm,image_datasets['test'].classes)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "tensor([[417.,  39.],\n",
            "        [ 25., 431.]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}