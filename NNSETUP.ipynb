{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNSETUP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5RvV1TKWyyQ84SHJ8FpkC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Orasz/BIMCV-COVID19/blob/main/NNSETUP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBI_OrLbgqk1"
      },
      "source": [
        "**SETUP AND MODULES IMPORT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRpzKVbDfnZ6",
        "outputId": "ce189d23-e249-4a99-b58d-555d7e7972ed"
      },
      "source": [
        "#@title Run on TensorFlow 2.x\r\n",
        "%tensorflow_version 2.x\r\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "#@title Import relevant modules\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# The following lines adjust the granularity of reporting. \r\n",
        "pd.options.display.max_rows = 10\r\n",
        "pd.options.display.float_format = \"{:.1f}\".format\r\n",
        "\r\n",
        "print(\"Imported modules.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imported modules.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVsahdxJg5dK"
      },
      "source": [
        "Load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YImX7kaug0Cc"
      },
      "source": [
        "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\r\n",
        "train_df = train_df.reindex(np.random.permutation(train_df.index)) # shuffle the examples\r\n",
        "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgWwgEKUhBOt"
      },
      "source": [
        "Define the plotting function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bmLDScIhD51"
      },
      "source": [
        "#@title Define the plotting function.\r\n",
        "\r\n",
        "def plot_the_loss_curve(epochs, mse):\r\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\r\n",
        "\r\n",
        "  plt.figure()\r\n",
        "  plt.xlabel(\"Epoch\")\r\n",
        "  plt.ylabel(\"Mean Squared Error\")\r\n",
        "\r\n",
        "  plt.plot(epochs, mse, label=\"Loss\")\r\n",
        "  plt.legend()\r\n",
        "  plt.ylim([mse.min()*0.95, mse.max() * 1.03])\r\n",
        "  plt.show()  \r\n",
        "\r\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7ItxFdZhI5G"
      },
      "source": [
        "define function to create and train linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foF9RItMhL4V"
      },
      "source": [
        "#@title Define functions to create and train a linear regression model\r\n",
        "def create_model(my_learning_rate, feature_layer):\r\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\r\n",
        "  # Most simple tf.keras models are sequential.\r\n",
        "  model = tf.keras.models.Sequential()\r\n",
        "\r\n",
        "  # Add the layer containing the feature columns to the model.\r\n",
        "  model.add(feature_layer)\r\n",
        "\r\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\r\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\r\n",
        "\r\n",
        "  # Construct the layers into a model that TensorFlow can execute.\r\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\r\n",
        "                loss=\"mean_squared_error\",\r\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\r\n",
        "\r\n",
        "  return model           \r\n",
        "\r\n",
        "\r\n",
        "def train_model(model, dataset, epochs, batch_size, label_name):\r\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\r\n",
        "\r\n",
        "  # Split the dataset into features and label.\r\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\r\n",
        "  label = np.array(features.pop(label_name))\r\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\r\n",
        "                      epochs=epochs, shuffle=True)\r\n",
        "\r\n",
        "  # Get details that will be useful for plotting the loss curve.\r\n",
        "  epochs = history.epoch\r\n",
        "  hist = pd.DataFrame(history.history)\r\n",
        "  rmse = hist[\"mean_squared_error\"]\r\n",
        "\r\n",
        "  return epochs, rmse   \r\n",
        "\r\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfrhSqHAhUIT"
      },
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQQwJafxhVIY"
      },
      "source": [
        "# The following variables are the hyperparameters.\r\n",
        "learning_rate = 0.01\r\n",
        "epochs = 15\r\n",
        "batch_size = 1000\r\n",
        "label_name = \"median_house_value\"\r\n",
        "\r\n",
        "# Establish the model's topography.\r\n",
        "my_model = create_model(learning_rate, my_feature_layer)\r\n",
        "\r\n",
        "# Train the model on the normalized training set.\r\n",
        "epochs, mse = train_model(my_model, train_df_norm, epochs, batch_size, label_name)\r\n",
        "plot_the_loss_curve(epochs, mse)\r\n",
        "\r\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\r\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\r\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\r\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7p-YpemhXVQ"
      },
      "source": [
        "Define a deep neural net:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnxhNbdzhZyU"
      },
      "source": [
        "def create_model(my_learning_rate, my_feature_layer):\r\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\r\n",
        "  # Most simple tf.keras models are sequential.\r\n",
        "  model = tf.keras.models.Sequential()\r\n",
        "\r\n",
        "  # Add the layer containing the feature columns to the model.\r\n",
        "  model.add(my_feature_layer)\r\n",
        "\r\n",
        "  # Describe the topography of the model by calling the tf.keras.layers.Dense\r\n",
        "  # method once for each layer. We've specified the following arguments:\r\n",
        "  #   * units specifies the number of nodes in this layer.\r\n",
        "  #   * activation specifies the activation function (Rectified Linear Unit).\r\n",
        "  #   * name is just a string that can be useful when debugging.\r\n",
        "\r\n",
        "  # Define the first hidden layer with 20 nodes.   \r\n",
        "  model.add(tf.keras.layers.Dense(units=20, \r\n",
        "                                  activation='relu', \r\n",
        "                                  name='Hidden1'))\r\n",
        "  \r\n",
        "  # Define the second hidden layer with 12 nodes. \r\n",
        "  model.add(tf.keras.layers.Dense(units=12, \r\n",
        "                                  activation='relu', \r\n",
        "                                  name='Hidden2'))\r\n",
        "  \r\n",
        "  # Define the output layer.\r\n",
        "  model.add(tf.keras.layers.Dense(units=1,  \r\n",
        "                                  name='Output'))                              \r\n",
        "  \r\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\r\n",
        "                loss=\"mean_squared_error\",\r\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUozEnW7hchN"
      },
      "source": [
        "define a training function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUf_OTtbheGU"
      },
      "source": [
        "def train_model(model, dataset, epochs, label_name,\r\n",
        "                batch_size=None):\r\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\r\n",
        "\r\n",
        "  # Split the dataset into features and label.\r\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\r\n",
        "  label = np.array(features.pop(label_name))\r\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\r\n",
        "                      epochs=epochs, shuffle=True) \r\n",
        "\r\n",
        "  # The list of epochs is stored separately from the rest of history.\r\n",
        "  epochs = history.epoch\r\n",
        "  \r\n",
        "  # To track the progression of training, gather a snapshot\r\n",
        "  # of the model's mean squared error at each epoch. \r\n",
        "  hist = pd.DataFrame(history.history)\r\n",
        "  mse = hist[\"mean_squared_error\"]\r\n",
        "\r\n",
        "  return epochs, mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FrP9_cNhhdy"
      },
      "source": [
        "call the training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IHOH3v2hjGU"
      },
      "source": [
        "# The following variables are the hyperparameters.\r\n",
        "learning_rate = 0.01\r\n",
        "epochs = 20\r\n",
        "batch_size = 1000\r\n",
        "\r\n",
        "# Specify the label\r\n",
        "label_name = \"median_house_value\"\r\n",
        "\r\n",
        "# Establish the model's topography.\r\n",
        "my_model = create_model(learning_rate, my_feature_layer)\r\n",
        "\r\n",
        "# Train the model on the normalized training set. We're passing the entire\r\n",
        "# normalized training set, but the model will only use the features\r\n",
        "# defined by the feature_layer.\r\n",
        "epochs, mse = train_model(my_model, train_df_norm, epochs, \r\n",
        "                          label_name, batch_size)\r\n",
        "plot_the_loss_curve(epochs, mse)\r\n",
        "\r\n",
        "# After building a model against the training set, test that model\r\n",
        "# against the test set.\r\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\r\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\r\n",
        "print(\"\\n Evaluate the new model against the test set:\")\r\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4eGhGcdhq3G"
      },
      "source": [
        "model tuned with regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWiQkqZ7htam"
      },
      "source": [
        "#@title Double-click for a possible solution\r\n",
        "\r\n",
        "# The following \"solution\" uses L2 regularization to bring training loss\r\n",
        "# and test loss closer to each other. Many, many other solutions are possible.\r\n",
        "\r\n",
        "\r\n",
        "def create_model(my_learning_rate, my_feature_layer):\r\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\r\n",
        "\r\n",
        "  # Discard any pre-existing version of the model.\r\n",
        "  model = None\r\n",
        "\r\n",
        "  # Most simple tf.keras models are sequential.\r\n",
        "  model = tf.keras.models.Sequential()\r\n",
        "\r\n",
        "  # Add the layer containing the feature columns to the model.\r\n",
        "  model.add(my_feature_layer)\r\n",
        "\r\n",
        "  # Describe the topography of the model. \r\n",
        "\r\n",
        "  # Implement L2 regularization in the first hidden layer.\r\n",
        "  model.add(tf.keras.layers.Dense(units=20, \r\n",
        "                                  activation='relu',\r\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(0.04),\r\n",
        "                                  name='Hidden1'))\r\n",
        "  \r\n",
        "  # Implement L2 regularization in the second hidden layer.\r\n",
        "  model.add(tf.keras.layers.Dense(units=12, \r\n",
        "                                  activation='relu', \r\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(0.04),\r\n",
        "                                  name='Hidden2'))\r\n",
        "\r\n",
        "  # Define the output layer.\r\n",
        "  model.add(tf.keras.layers.Dense(units=1,  \r\n",
        "                                  name='Output'))                              \r\n",
        "  \r\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\r\n",
        "                loss=\"mean_squared_error\",\r\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\r\n",
        "\r\n",
        "  return model     \r\n",
        "\r\n",
        "# Call the new create_model function and the other (unchanged) functions.\r\n",
        "\r\n",
        "# The following variables are the hyperparameters.\r\n",
        "learning_rate = 0.007\r\n",
        "epochs = 140\r\n",
        "batch_size = 1000\r\n",
        "\r\n",
        "label_name = \"median_house_value\"\r\n",
        "\r\n",
        "# Establish the model's topography.\r\n",
        "my_model = create_model(learning_rate, my_feature_layer)\r\n",
        "\r\n",
        "# Train the model on the normalized training set.\r\n",
        "epochs, mse = train_model(my_model, train_df_norm, epochs, \r\n",
        "                          label_name, batch_size)\r\n",
        "plot_the_loss_curve(epochs, mse)\r\n",
        "\r\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\r\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\r\n",
        "print(\"\\n Evaluate the new model against the test set:\")\r\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtTb1poDhqsF"
      },
      "source": [
        ""
      ]
    }
  ]
}